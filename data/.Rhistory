if((row[3] == 0)){
s2 <- as.numeric(char[row[2]])
}
else{
s2 <- as.numeric(two_char[paste0(substr(row[1], row[3], row[3]), row[2])])
}
return(s1/s2)
}
# freq(c)
score.2 <- function(row) {
freqc <- as.numeric(tf[tf$term == row[4], 2])
return(freqc)
}
# Add score to deletion candidate
final_final <- cbind(final_final, as.vector(apply(final_final, 1, score.2)))
final_final <- cbind(final_final, as.vector(apply(final_final, 1, score.1, cm = cm)))
final_final <- final_final[, -c(2, 3)]
final_final <- cbind(final_final, as.numeric(final_final[, 3])*as.numeric(final_final[, 4]))
final_final <- final_final[, c(1, 2, 5, 3, 4)]
colnames(final_final) <- c("error", "cor", "Rawscore", "freq(cor)", "Pr(t/c)")
final_final[1, 4]
tf$term == "ab"
tf[tf$term == "ab", 2]
as.numeric(tf[tf$term == "ab", 2])
final_final <- as.matrix(cbind(delete_candidate, Word = final_deletion_can[, 2])) # deletion candidate without score
score.2(final_final[1, ])
final_final <- cbind(final_final, as.vector(apply(final_final, 1, score.2)))
final_final <- cbind(final_final, as.vector(apply(final_final, 1, score.1, cm = cm)))
final_final
final_final <- final_final[, -c(2, 3)]
final_final <- cbind(final_final, as.numeric(final_final[, 3])*as.numeric(final_final[, 4]))
final_final
as.numeric(final_final[, 3])*as.numeric(final_final[, 4]
)
as.numeric(final_final[, 3])
as.numeric(final_final[, 4])
View(final_deletion_can)
View(final_final)
View(deltable)
sub_matrix
rownames(sub_matrix) <- letters
results_sub <- function(error){
y<- sub_can(error)
df <- data.frame(y[,1:2])
for (i in 1: nrow(sub_can(error))){
x <- sub_can(error)[i,]
prior <- (tf[tf$term==x$words,]$n + 0.5)/(300847+16902)
p_t_c <- as.numeric(sub_matrix[x$typo,x$cor])/as.numeric(char[x$cor])
df[i, 3] <- prior*p_t_c
df[i, 4] <- tf[tf$term==x$words,]$n
df[i,5] <- p_t_c
}
colnames(df) <- c("error","cor","Rawscore", "freq(cor)","Pr(t/c)")
return(df)
}
new_false_word <- unique(false_word[sapply(false_word,str_detect,"^[[:alpha:]]{1,}+$" )])
var <- c()
for (i in 1: length(new_false_word)){
if (nrow(sub_can(new_false_word[i]))>0){
var <- append(var, new_false_word[i])
}
}
sub_candidate <- lapply(var, results_sub)
results_sub('by')
new_false_word
new_false_word <- unique(false_word[sapply(false_word,str_detect,"^[[:alpha:]]{1,}+$" )])
var <- c()
for (i in 1: length(new_false_word)){
if (nrow(sub_can(new_false_word[i]))>0){
var <- append(var, new_false_word[i])
}
}
sub_candidate <- lapply(var, results_sub)
deltable <- deltable[deltable$Correction %in% letters, ]
final_final <- as.matrix(cbind(delete_candidate, Word = final_deletion_can[, 2])) # deletion candidate without score
final_final <- cbind(final_final, as.vector(apply(final_final, 1, score.2)))
final_final <- cbind(final_final, as.vector(apply(final_final, 1, score.1, cm = cm)))
final_final <- final_final[, -c(2, 3)]
final_final <- cbind(final_final, as.numeric(final_final[, 3])*as.numeric(final_final[, 4]))
View(deltable)
two_char['al']
delete_choice <- lapply(false_word, get_deletion)
delete_choice <- delete_choice[!is.na(delete_choice)]
delete_candidate <- ldply(delete_choice) # deletion candidate as data frame
delete_candidate <- unique(delete_candidate)
final_deletion_can <- (t(apply(delete_candidate, 1, correction)))
final_final <- as.matrix(cbind(delete_candidate, Word = final_deletion_can[, 2])) # deletion candidate without score
final_final <- cbind(final_final, as.vector(apply(final_final, 1, score.2)))
final_final <- cbind(final_final, as.vector(apply(final_final, 1, score.1, cm = cm)))
final_final <- final_final[, -c(2, 3)]
final_final <- cbind(final_final, as.numeric(final_final[, 3])*as.numeric(final_final[, 4]))
final_final <- final_final[, c(1, 2, 5, 3, 4)]
colnames(final_final) <- c("error", "cor", "Rawscore", "freq(cor)", "Pr(t/c)")
new_false_word
sub_matrix
results_sub <- function(error){
y<- sub_can(error)
df <- data.frame(y[,1:2])
for (i in 1: nrow(sub_can(error))){
x <- sub_can(error)[i,]
prior <- (tf[tf$term==x$words,]$n + 0.5)/(300847+16902)
p_t_c <- as.numeric(sub_matrix[x$typo,x$cor])/as.numeric(char[x$cor])
df[i, 3] <- prior*p_t_c
df[i, 4] <- tf[tf$term==x$words,]$n
df[i,5] <- p_t_c
}
colnames(df) <- c("error","cor","Rawscore", "freq(cor)","Pr(t/c)")
return(df)
}
new_false_word <- unique(false_word[sapply(false_word,str_detect,"^[[:alpha:]]{1,}+$" )])
var <- c()
for (i in 1: length(new_false_word)){
if (nrow(sub_can(new_false_word[i]))>0){
var <- append(var, new_false_word[i])
}
}
sub_candidate <- lapply(var, results_sub)
results_sub('by')
new_false_word
var
rownames(sub_matrix) <- letters
substitution <- function(error, letter, i){
x <- strsplit(error, split = "")[[1]][i]
substr(error, i, i) <- letter
return(c(error, letter, x))
}
sub_can <- function(error){
word_list <- list()
for (i in 1: nchar(error)){
ith_list <- sapply(letters, substitution, error=error, i=i)
word_list[[i]] <- ith_list
}
x <- matrix(unlist(word_list), ncol = 3, byrow = T)
colnames(x) <- c('words', 'cor', 'typo')
merge_words <-  merge(x, dict, by.x ='words', by.y ='words' )
error_num <- rep(error, nrow(merge_words))
return(cbind(error_num, merge_words))
}
results_sub <- function(error){
y<- sub_can(error)
df <- data.frame(y[,1:2])
for (i in 1: nrow(sub_can(error))){
x <- sub_can(error)[i,]
prior <- (tf[tf$term==x$words,]$n + 0.5)/(300847+16902)
p_t_c <- as.numeric(sub_matrix[x$typo,x$cor])/as.numeric(char[x$cor])
df[i, 3] <- prior*p_t_c
df[i, 4] <- tf[tf$term==x$words,]$n
df[i,5] <- p_t_c
}
colnames(df) <- c("error","cor","Rawscore", "freq(cor)","Pr(t/c)")
return(df)
}
new_false_word <- unique(false_word[sapply(false_word,str_detect,"^[[:alpha:]]{1,}+$" )])
var <- c()
for (i in 1: length(new_false_word)){
if (nrow(sub_can(new_false_word[i]))>0){
var <- append(var, new_false_word[i])
}
}
var
results_sub('by')
sub_candidate <- lapply(var, results_sub)
sub_matrix
sub_matrix['a','i']
x <- sub_can('by')[1,]
x
sub_matrix[x$typo,x$cor]
x$typo
sub_matrix['b','a']
str(x$typo)
results_sub <- function(error){
y<- sub_can(error)
df <- data.frame(y[,1:2])
for (i in 1: nrow(sub_can(error))){
x <- sub_can(error)[i,]
prior <- (tf[tf$term==x$words,]$n + 0.5)/(300847+16902)
p_t_c <- as.numeric(sub_matrix[as.character(x$typo),as.character(x$cor)])/as.numeric(char[x$cor])
df[i, 3] <- prior*p_t_c
df[i, 4] <- tf[tf$term==x$words,]$n
df[i,5] <- p_t_c
}
colnames(df) <- c("error","cor","Rawscore", "freq(cor)","Pr(t/c)")
return(df)
}
new_false_word <- unique(false_word[sapply(false_word,str_detect,"^[[:alpha:]]{1,}+$" )])
var <- c()
for (i in 1: length(new_false_word)){
if (nrow(sub_can(new_false_word[i]))>0){
var <- append(var, new_false_word[i])
}
}
var
results_sub('by')
sub_candidate <- lapply(var, results_sub)
as.numeric(final_final[, 3])*as.numeric(final_final[, 4]
as.numeric(final_final[, 3])*as.numeric(final_final[, 4])
sub_matrix[as.character(x$typo),as.character(x$cor)])
ub_matrix[as.character(x$typo),as.character(x$cor)]
sub_matrix[as.character(x$typo),as.character(x$cor)]
results_sub <- function(error){
y<- sub_can(error)
df <- data.frame(y[,1:2])
for (i in 1: nrow(sub_can(error))){
x <- sub_can(error)[i,]
prior <- (tf[tf$term==x$words,]$n + 0.5)/(300847+16902)
p_t_c <- as.numeric(sub_matrix[as.character(x$typo),as.character(x$cor)])/as.numeric(char[x$cor])
df[i, 3] <- prior*p_t_c
df[i, 4] <- tf[tf$term==x$words,]$n
df[i,5] <- p_t_c
}
colnames(df) <- c("error","cor","Rawscore", "freq(cor)","Pr(t/c)")
return(df)
}
new_false_word <- unique(false_word[sapply(false_word,str_detect,"^[[:alpha:]]{1,}+$" )])
var <- c()
for (i in 1: length(new_false_word)){
if (nrow(sub_can(new_false_word[i]))>0){
var <- append(var, new_false_word[i])
}
}
var
rownames(sub_matrix) <- letters
substitution <- function(error, letter, i){
x <- strsplit(error, split = "")[[1]][i]
substr(error, i, i) <- letter
return(c(error, letter, x))
}
sub_can <- function(error){
word_list <- list()
for (i in 1: nchar(error)){
ith_list <- sapply(letters, substitution, error=error, i=i)
word_list[[i]] <- ith_list
}
x <- matrix(unlist(word_list), ncol = 3, byrow = T)
colnames(x) <- c('words', 'cor', 'typo')
merge_words <-  merge(x, dict, by.x ='words', by.y ='words' )
error_num <- rep(error, nrow(merge_words))
return(cbind(error_num, merge_words))
}
results_sub <- function(error){
y<- sub_can(error)
df <- data.frame(y[,1:2])
for (i in 1: nrow(sub_can(error))){
x <- sub_can(error)[i,]
prior <- (tf[tf$term==x$words,]$n + 0.5)/(300847+16902)
p_t_c <- as.numeric(sub_matrix[as.character(x$typo),as.character(x$cor)])/as.numeric(char[x$cor])
df[i, 3] <- prior*p_t_c
df[i, 4] <- tf[tf$term==x$words,]$n
df[i,5] <- p_t_c
}
colnames(df) <- c("error","cor","Rawscore", "freq(cor)","Pr(t/c)")
return(df)
}
new_false_word <- unique(false_word[sapply(false_word,str_detect,"^[[:alpha:]]{1,}+$" )])
var <- c()
for (i in 1: length(new_false_word)){
if (nrow(sub_can(new_false_word[i]))>0){
var <- append(var, new_false_word[i])
}
}
var
results_sub('by')
sub_candidate <- lapply(var, results_sub)
sub_candidate
results_sub('by')
sub_candidate <- lapply(var, results_sub)
new_false_word
var
for (i in length(var)){
print(return(results_sub(var[i])))
}
for (i in 1:length(var)){
print(return(results_sub(var[i])))
}
length(var)
for (i in 1:length(var)){
print(return(results_sub(var[i])))
}
var[1]
for ( i in 1:length(var)){
print(results_sub(var[i]))
}
results_sub('pry')
sub_can('pry')
results_sub('pry')
str(sub_matrix)
sub_matrix
results_sub <- function(error){
y<- sub_can(error)
df <- data.frame(y[,1:2])
for (i in 1: nrow(sub_can(error))){
x <- sub_can(error)[i,]
prior <- (tf[tf$term==x$words,]$n + 0.5)/(300847+16902)
p_t_c <- as.numeric(sub_matrix[(x$typo),(x$cor)])/as.numeric(char[x$cor])
df[i, 3] <- prior*p_t_c
df[i, 4] <- tf[tf$term==x$words,]$n
df[i,5] <- p_t_c
}
colnames(df) <- c("error","cor","Rawscore", "freq(cor)","Pr(t/c)")
return(df)
}
results_sub('pry')
sub_can('pry')
sub_can('pry')$word
x <- sub_can('pry')[1,]
x
(tf[tf$term==x$words,]$n + 0.5)/(300847+16902)
as.numeric(sub_matrix[(x$typo),(x$cor)])/as.numeric(char[x$cor])
tf[tf$term==x$words,]$n
results_sub('pry')
y <- sub_can('pry')
data.frame(y[,1:2])
library(plyr)
df <- rbind(df1, df2)
df <- split(result_df, f = result_df$originalerror)
find <- function(df){
if(nrow(df[df$Rawscore == max(df$Rawscore), ]) != 1){
df <- df[df$`freq(cor)` == max(df$`freq(cor)`), ]
}
else{
df <- df[df$Rawscore == max(df$Rawscore), ]
}
}
result <- ldply(lapply(df, find), data.frame)
df <- rbind(result_df, final_final)
df <- split(df, f = result_df$originalerror)
if (!require("devtools")) install.packages("devtools")
if (!require("pacman")) {
## devtools is required
library(devtools)
install_github("trinker/pacman")
}
pacman::p_load(knitr, readr, stringr, tesseract, vecsets)
source('../lib/ifCleanToken.R')
file_name_vec <- list.files("../data/ground_truth") #100 files in total
### only process one of the files in the folder as an example, in your project, you need to use all the files
current_file_name <- sub(".txt", "", file_name_vec[5])
## read the ground truth text
current_ground_truth_txt <- readLines(paste("../data/ground_truth/",current_file_name,".txt",sep=""), warn=FALSE)
## read the tesseract text
current_tesseract_txt <- readLines(paste("../data/tesseract/",current_file_name,".txt",sep=""), warn=FALSE)
clean_tesseract_txt <- paste(current_tesseract_txt, collapse = " ")
## detect tesseract word error
tesseract_vec <- str_split(clean_tesseract_txt," ")[[1]] #1124 tokens
tesseract_if_clean <- unlist(lapply(tesseract_vec, ifCleanToken)) # source code of ifCleanToken in in lib folder
sum(tesseract_if_clean == TRUE)
sum(tesseract_if_clean == FALSE)
false_word <- tolower(tesseract_vec[which(tesseract_if_clean==FALSE)])
rownames(sub_matrix) <- letters
sub_matrix <- read.csv('sub_matrix')
getwd()
sub_matrix <- read.csv('sub_matrix.csv')
rownames(sub_matrix) <- letters
substitution <- function(error, letter, i){
x <- strsplit(error, split = "")[[1]][i]
substr(error, i, i) <- letter
return(c(error, letter, x))
}
sub_can <- function(error){
word_list <- list()
for (i in 1: nchar(error)){
ith_list <- sapply(letters, substitution, error=error, i=i)
word_list[[i]] <- ith_list
}
x <- matrix(unlist(word_list), ncol = 3, byrow = T)
colnames(x) <- c('words', 'cor', 'typo')
merge_words <-  merge(x, dict, by.x ='words', by.y ='words' )
error_num <- rep(error, nrow(merge_words))
return(cbind(error_num, merge_words))
}
results_sub <- function(error){
y<- sub_can(error)
df <- data.frame(y[,1:2])
for (i in 1: nrow(sub_can(error))){
x <- sub_can(error)[i,]
prior <- (tf[tf$term==x$words,]$n + 0.5)/(300847+16902)
p_t_c <- as.numeric(sub_matrix[(x$typo),(x$cor)])/as.numeric(char[x$cor])
df[i, 3] <- prior*p_t_c
df[i, 4] <- tf[tf$term==x$words,]$n
df[i,5] <- p_t_c
}
colnames(df) <- c("error","cor","Rawscore", "freq(cor)","Pr(t/c)")
return(df)
}
new_false_word <- unique(false_word[sapply(false_word,str_detect,"^[[:alpha:]]{1,}+$" )])
var <- c()
for (i in 1: length(new_false_word)){
if (nrow(sub_can(new_false_word[i]))>0){
var <- append(var, new_false_word[i])
}
}
library(dplyr)
files <- list.files(path="/Users/Boris/Documents/GitHub/Fall2018-Project4-sec2--sec2proj4_grp9/data/ground_truth",pattern = '*.txt', full.names =TRUE  )
words <- c()
for (file in files ){
text <- readLines(file, warn = F)
text <- paste(text, collapse = " ")
text.words <- strsplit(text, split = "(\\s|[[:punct:]])+")[[1]]
words <- append(words, text.words)
}
words <- tolower(words)
head(words) # the dictionary without duplication
fq_table <- table(words) # the frequency of words from table function
N <- length(words) # how many words in ground truth
N
vocabulary <- unique(words) # the unique words in dictionary
V  <- length(vocabulary)  # the number of unique words
V
dict <- matrix(vocabulary, ncol = 1)
colnames(dict) <- 'words'
head(dict)            # the dictionary made from matrix
new_false_word <- unique(false_word[sapply(false_word,str_detect,"^[[:alpha:]]{1,}+$" )])
var <- c()
for (i in 1: length(new_false_word)){
if (nrow(sub_can(new_false_word[i]))>0){
var <- append(var, new_false_word[i])
}
}
var
results_sub('pry')
frequency <- data_frame(words, ncol = 1)
colnames(frequency) <- c("words","n")
head(frequency, 20)
tf <-  frequency %>%
count(words, sort = T)
head(tf, 20)
frequency <- data_frame(words, ncol = 1)
colnames(frequency) <- c("words","n")
head(frequency, 20)
tf <-  frequency %>%
count(words, sort = T)
tf <-  frequency %>%
count(words, sort = TRUE)
library(dplyr)
tf <-  frequency %>%
count(words, sort = T)
tf <-  frequency %>%
count(words)
frequency
tf <-  frequency %>%
count(words)
load("/Users/Boris/Documents/GitHub/Fall2018-Project4-sec2--sec2proj4_grp9/data/tf.RData")
results_sub('pry')
load("/Users/Boris/Documents/GitHub/Fall2018-Project4-sec2--sec2proj4_grp9/data/char.RData")
results_sub('pry')
knitr::opts_chunk$set(echo = TRUE)
false_word <- tolower(tesseract_vec[which(tesseract_if_clean==FALSE)])
length(false_word)
# the insertion,delete the character from the error,find candicates
aftermake = data.frame()
for (i in 1:length(false_word)){
thisstr1 = false_word[i]
thisstr = tolower(false_word[i])
n = length(unlist(strsplit(thisstr, "")))
thisvec = c()
for (j in 1:n){
thismake1 = unlist(strsplit(thisstr, ""))[-j]
thismake2 = paste(thismake1, sep = "",collapse = "")
thisvec[j] = thismake2
}
thisdf_inser = data.frame(thisvec)
thisdf = cbind(rep(thisstr1,nrow(thisdf_inser)),thisdf_inser)
colnames(thisdf) = c("error","insertion")
thisdf$error = as.character(thisdf$error)
thisdf$insertion = as.character(thisdf$insertion)
aftermake = rbind(aftermake,thisdf)
}
aftermake$error  = as.character(aftermake$error)
aftermake$insertion = as.character(aftermake$insertion)
aftermake_df = data_frame(as.character(unlist(aftermake$insertion)))
colnames(aftermake_df) = "words"
#aftermake_df
#aftermake
# confusion matrix of insertion typo
add_mat = read.csv(file = "/Users/Boris/Documents/GitHub/Fall2018-Project4-sec2--sec2proj4_grp9/data/add_matrix.csv")
# the dictionary and charx
library(dplyr)
files <- list.files(path='/Users/Boris/Documents/GitHub/Fall2018-Project4-sec2--sec2proj4_grp9/data/ground_truth',pattern = '*.txt', full.names =TRUE  )
words <- c()
for (file in files ){
file
text <- readLines(file, warn = F)
text <- paste(text, collapse = " ")
text.words <- strsplit(text, split = "(\\s|[[:punct:]])+")[[1]]
words <- append(words, text.words)
}
words <- tolower(words)
head(words) # the dictionary without duplication
fq_table <- table(words) # the frequency of words from table function
N <- length(words) # how many words in ground truth
N
vocabulary <- unique(words) # the unique words in dictionary
V  <- length(vocabulary)  # the number of unique words
V
dict <- data.frame(matrix(vocabulary, ncol = 1))
colnames(dict) <- 'words'
head(dict)            # the dictionary made from matrix
frequency <- data_frame(words, ncol=1)
colnames(frequency) <- c("words",'n')
head(frequency, 20)
frequency
char <- table(strsplit(paste(words, collapse = ""), split = "")[[1]])[letters] # the chars for every character
# find the insertion correction that in dictionary
library(plyr)
corrections = aftermake_df%>%
inner_join(dict)
freq_c = c()
for (i in 1:nrow(unique(corrections))){
thiscor = as.character(unique(corrections)[i,])
r = as.numeric(tf[tf$words == thiscor,'nn'])
freq_c = c(freq_c,r+0.5)
}
